epochs = 100
train_losses = []
val_losses = []
train_r2 = []
val_r2 = []

for epoch in range(epochs):
    train_loss = 0.0
    train_target = []
    val_target = []
    train_predict = []
    val_predict = []

    # Training phase
    MLP.train()
    for X_samples, y_samples in train_loader:
        X_samples = X_samples.to(device)
        y_samples = y_samples.to(device)

        # Zero the gradients
        optimizer.zero_grad()

        # Forward pass
        outputs = MLP(X_samples)

        # Store predictions and targets
        train_predict += outputs.tolist()
        train_target += y_samples.tolist()

        # Compute loss
        loss = criterion(outputs, y_samples)

        # Backward pass
        loss.backward()

        # Update weights
        optimizer.step()

        # Accumulate loss
        train_loss += loss.item()

    # Average training loss
    train_loss /= len(train_loader)
    train_losses.append(train_loss)

    # Calculate R² score for training
    train_r2.append(r_squared(train_target, train_predict))

    # Validation phase
    MLP.eval()
    val_loss = 0.0
    with torch.no_grad():
        for X_samples, y_samples in val_loader:
            X_samples = X_samples.to(device)
            y_samples = y_samples.to(device)

            # Forward pass
            outputs = MLP(X_samples)

            # Store predictions and targets
            val_predict += outputs.tolist()
            val_target += y_samples.tolist()

            # Compute loss
            loss = criterion(outputs, y_samples)

            # Accumulate loss
            val_loss += loss.item()

    # Average validation loss
    val_loss /= len(val_loader)
    val_losses.append(val_loss)

    # Calculate R² score for validation
    val_r2.append(r_squared(val_target, val_predict))

    # Print epoch summary
    print(f"\nEPOCH {epoch + 1}:\tTraining loss: {train_loss:.3f}\tValidation loss: {val_loss:.3f}")